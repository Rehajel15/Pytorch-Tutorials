{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMgVG91KXP/TvKuV7xeGNn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rehajel15/Pytorch-Tutorials/blob/main/01_pytorch_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Workflow\n",
        "\n",
        "Let's explore an example PyTorch end-to-end workflow\n",
        "\n",
        "Resources:\n",
        "* Ground truth notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow.ipynb\n",
        "* Book version of notebook - https://www.learnpytorch.io/01_pytorch_workflow/\n",
        "* Ask a question - https://github.com/mrdbourke/pytorch-deep-learning/discussions"
      ],
      "metadata": {
        "id": "LmLDcLS4_f7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "what_were_covering = {1: \"data (prepare and load)\",\n",
        "                      2: \"build model\",\n",
        "                      3: \"fitting model to data (training)\",\n",
        "                      4: \"making predictions and evaluting a model (inference)\",\n",
        "                      5: \"saving and loading a model\",\n",
        "                      6: \"putting it all together\"}\n",
        "\n",
        "what_were_covering"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_LFGruOAeA-",
        "outputId": "5d9683a4-4dda-4c70-a982-4880527570b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'data (prepare and load)',\n",
              " 2: 'build model',\n",
              " 3: 'fitting model to data (training)',\n",
              " 4: 'making predictions and evaluting a model (inference)',\n",
              " 5: 'saving and loading a model',\n",
              " 6: 'putting it all together'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RGbKfCdIBJEO",
        "outputId": "f432b5f3-59d6-46f5-ee53-ceeb9e153a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data (preparing and loading)\n",
        "\n",
        "Data can be almost anything in machine learning\n",
        "* Excel spreadsheet\n",
        "* Images of any kind\n",
        "* Videos (YouTube has lots of data...)\n",
        "* Audio like songs or podcast\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "Machne learning is a game of two parts:\n",
        "1. Get data into a numerical representation.\n",
        "2. Build a model to learn patterns in that numerical representation.\n",
        "\n",
        "To showcase this, let's create some *known* data using the linear regression formula.\n",
        "\n",
        "We'll use a linear regression formula to make a straight line with *known* **parameters**."
      ],
      "metadata": {
        "id": "Z_2L1yBTBvPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgOEHyxYCuF4",
        "outputId": "104f4930-6afa-4534-9317-a1bdf2257fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQpIDp24EIRf",
        "outputId": "ff3c20ce-44ac-4a7d-f99c-ef643268baaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test sets (one of the most important concepts in machine learning in general)\n",
        "\n",
        "Let's create a training and a test set with our data"
      ],
      "metadata": {
        "id": "0jS6LQOLEU_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train/test split\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgFwNbTyh57p",
        "outputId": "1a8bfadb-de94-4923-f80b-1765e4390302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How might we better visualize our data?\n",
        "\n",
        "This is where the data explorer's motto comes in!\n",
        "\n",
        "\"Visualize, visualize, visualize!\""
      ],
      "metadata": {
        "id": "371OXBI5lDhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(10,7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions if they exists\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\":14})"
      ],
      "metadata": {
        "id": "sookKaYvlz12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "NpNtEN2GoPXH",
        "outputId": "c8eb4721-07b7-49de-8597-7bf09d7cb3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build model\n",
        "\n",
        "Our first PyTorch model!\n",
        "\n",
        "This is very exciting... let's do it!\n",
        "\n",
        "Because we're going to be building classes throughout the course, I'd recommend getting familiar with OOP in Python, to do so you can use the following resource from Real Python: https://realpython.com/python3-object-oriented-programming/\n",
        "\n",
        "What our model does:\n",
        "* Start with random values (weight & bias)\n",
        "* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight & bias values we used to create the data)\n",
        "\n",
        "How does it do so?\n",
        "\n",
        "Through two main algorithms:\n",
        "1. Gradient descent - https://youtu.be/IHZwWFHWa-w\n",
        "2. Backpropagation - https://youtu.be/Ilg3gGewQ5U\n",
        "\n"
      ],
      "metadata": {
        "id": "TyPI_DhYoSCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a linear regression model class\n",
        "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch inherhits from nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Initialize model parameters\n",
        "    self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "  # Forward method to define the computation in the model\n",
        "  def forward(self, x:torch.Tensor) -> torch.Tensor: # <- x is the input data\n",
        "    return self.weights * x + self.bias # This is the linear regression formula\n"
      ],
      "metadata": {
        "id": "eE81kfK8qVOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "* torch.nn - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
        "* torch.nn.Parameter - what parameters should our model try and learn, often a PyTorch layer from torch.nn will set these for us\n",
        "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
        "* torch.optim - this is where the optimizers in PyTorch live, they will help with gradient descent\n",
        "* def forward() - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation\n",
        "\n",
        "See more of these essential modules via the PyTorch cheatsheet - https://pytorch.org/tutorials/beginner/ptcheat.html"
      ],
      "metadata": {
        "id": "TpJfQl08LgI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the contents of our PyTorch model\n",
        "\n",
        "Now we've created a model, let's see what's inside...\n",
        "\n",
        "So we can checkout our model parameters or what's inside our model using `.paramters()`."
      ],
      "metadata": {
        "id": "9biDMylYCAh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFj21XD3Cm-F",
        "outputId": "49b22479-1e57-4cb0-ec52-eb429a1023a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPia4CjJDDyO",
        "outputId": "9549fe1d-7d93-43d3-8a84-bb4bc0d705e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making preditctions using `torch.inference_model()`\n",
        "To check our model's preditctive ower, let's see how well it predicts `y_test` based on `X_test`.\n",
        "\n",
        "When we pass data through our model, it's going to run it through the `forward()` method.\n"
      ],
      "metadata": {
        "id": "lVDyLvqMEBil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test,y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QveV6FqVFpqT",
        "outputId": "d58b06bf-499d-49d8-d756-7109f98765f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8000],\n",
              "         [0.8200],\n",
              "         [0.8400],\n",
              "         [0.8600],\n",
              "         [0.8800],\n",
              "         [0.9000],\n",
              "         [0.9200],\n",
              "         [0.9400],\n",
              "         [0.9600],\n",
              "         [0.9800]]),\n",
              " tensor([[0.8600],\n",
              "         [0.8740],\n",
              "         [0.8880],\n",
              "         [0.9020],\n",
              "         [0.9160],\n",
              "         [0.9300],\n",
              "         [0.9440],\n",
              "         [0.9580],\n",
              "         [0.9720],\n",
              "         [0.9860]]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predicitons with model\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "# You can also do something similar with torch.no_grad(), however, torch.inference_mode() is preferred\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iMgmG1-FRdb",
        "outputId": "bfae8b8e-b900-4dc2-c55f-eb3226365aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3982],\n",
              "        [0.4049],\n",
              "        [0.4116],\n",
              "        [0.4184],\n",
              "        [0.4251],\n",
              "        [0.4318],\n",
              "        [0.4386],\n",
              "        [0.4453],\n",
              "        [0.4520],\n",
              "        [0.4588]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See more on inference mode here - https://twitter.com/PyTorch/status/1437838231505096708?s=20&t=cnKav09iTgwQ-rfri6u7PQ"
      ],
      "metadata": {
        "id": "iwRrRCTzHlPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR5Y6pxYFfXl",
        "outputId": "347dd1a7-ec94-40da-f38c-86044ab0e326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8600],\n",
              "        [0.8740],\n",
              "        [0.8880],\n",
              "        [0.9020],\n",
              "        [0.9160],\n",
              "        [0.9300],\n",
              "        [0.9440],\n",
              "        [0.9580],\n",
              "        [0.9720],\n",
              "        [0.9860]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "v96uGSisGceI",
        "outputId": "725d7252-d62d-4f2e-c970-2d7c90932200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train model\n",
        "\n",
        "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters.\n",
        "\n",
        "Or in other words from a poor representation of the data to a better representation of the data.\n",
        "\n",
        "One way to measure how poor or how wrong your models predictions are is to use a loss function.\n",
        "\n",
        "* Note: Loss function may also be called cost function or criterion in different areas. For our case, we'Re going to refer to it as a loss function.\n",
        "\n",
        "Things we need to train:\n",
        "\n",
        "* **Loss function:** A function to measure how wrong your model predictions are to the ideal outputs, lower is better.\n",
        "* **Optimizer:** Takes into account the loss and adjust the model's parameters (e.g. weight & bias in our case) to improve the loss function.\n",
        "\n",
        "And specificallly for PyTorch, we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "8taoRmLkGsc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H59w-zResfiS",
        "outputId": "183f848f-e834-4bc7-c29d-fd6c6ba91272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model's parameters (a parameter is a value that the model sets itself)\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p5rHcDZsmXd",
        "outputId": "31925d88-b95d-4ba8-9523-858601d56c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Setup an optimizer (stochastic gradient descent)\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.001) # lr = learning rate = possibly the most important hyperparameter you can set\n"
      ],
      "metadata": {
        "id": "hHgupGH8spDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a training loop (and a testing loop) in PyTorch\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "0. Loop through the data and do...\n",
        "1. Forward pass (this envolves data moving through our model's `forward()` functions) to make predictions on data - also called forward propagation\n",
        "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (**backpropagation**)\n",
        "5. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss (**gradient descent**)"
      ],
      "metadata": {
        "id": "JkhJ5Cm1szah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An epoch is one loop through the data... (this is a hyperparameter because we've set it ourselves)\n",
        "epochs = 10000\n",
        "\n",
        "# Track different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "### Training\n",
        "# 0. Loop through the data\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # 3. Optimize zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation on the loss with respect to the parameters of the model\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (perform gradient descent)\n",
        "  optimizer.step() # by default how the optimizer changes will acculumate through the loop so... we have to zero them above in step 3 for the next iteration of the loop\n",
        "\n",
        "  ###Testing\n",
        "  model_0.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "  with torch.inference_mode(): # turns off gradient tracking & a couple of more things behind the scenes\n",
        "    # 1. Do the forward pass\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  # Print out what's happening\n",
        "  if epoch % 100 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")\n",
        "\n",
        "    # Print out model state_dict()\n",
        "    print(f\"Model state_dict(): {model_0.state_dict()}\")\n"
      ],
      "metadata": {
        "id": "p9mH0IJWxkaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173f13d3-8340-472c-ac5e-3b1e636413b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.31288138031959534 | Test loss: 0.4931890368461609\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.3371])), ('bias', tensor([0.1298]))])\n",
            "Epoch: 100 | Loss: 0.19767141342163086 | Test loss: 0.35847947001457214\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.3761])), ('bias', tensor([0.2298]))])\n",
            "Epoch: 200 | Loss: 0.08973254263401031 | Test loss: 0.22795839607715607\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.4150])), ('bias', tensor([0.3257]))])\n",
            "Epoch: 300 | Loss: 0.05357731133699417 | Test loss: 0.15086300671100616\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.4485])), ('bias', tensor([0.3730]))])\n",
            "Epoch: 400 | Loss: 0.04549176245927811 | Test loss: 0.11657620966434479\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.4730])), ('bias', tensor([0.3855]))])\n",
            "Epoch: 500 | Loss: 0.04160415381193161 | Test loss: 0.10088418424129486\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.4924])), ('bias', tensor([0.3839]))])\n",
            "Epoch: 600 | Loss: 0.03811401128768921 | Test loss: 0.08986451476812363\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.5104])), ('bias', tensor([0.3789]))])\n",
            "Epoch: 700 | Loss: 0.03466346859931946 | Test loss: 0.08097299933433533\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.5277])), ('bias', tensor([0.3724]))])\n",
            "Epoch: 800 | Loss: 0.03122851625084877 | Test loss: 0.07297395914793015\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.5448])), ('bias', tensor([0.3652]))])\n",
            "Epoch: 900 | Loss: 0.027794325724244118 | Test loss: 0.06490625441074371\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.5619])), ('bias', tensor([0.3580]))])\n",
            "Epoch: 1000 | Loss: 0.02435956709086895 | Test loss: 0.05690721794962883\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.5790])), ('bias', tensor([0.3508]))])\n",
            "Epoch: 1100 | Loss: 0.02092517353594303 | Test loss: 0.0488395169377327\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.5961])), ('bias', tensor([0.3437]))])\n",
            "Epoch: 1200 | Loss: 0.017490629106760025 | Test loss: 0.04084048420190811\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6131])), ('bias', tensor([0.3365]))])\n",
            "Epoch: 1300 | Loss: 0.014056024141609669 | Test loss: 0.03277278691530228\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6302])), ('bias', tensor([0.3293]))])\n",
            "Epoch: 1400 | Loss: 0.010621682740747929 | Test loss: 0.0247737355530262\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6473])), ('bias', tensor([0.3221]))])\n",
            "Epoch: 1500 | Loss: 0.007186878472566605 | Test loss: 0.01670604944229126\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6644])), ('bias', tensor([0.3150]))])\n",
            "Epoch: 1600 | Loss: 0.003752306802198291 | Test loss: 0.008672690019011497\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6815])), ('bias', tensor([0.3078]))])\n",
            "Epoch: 1700 | Loss: 0.0003177322505507618 | Test loss: 0.0006393313524313271\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6986])), ('bias', tensor([0.3006]))])\n",
            "Epoch: 1800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 1900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 2900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 3900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 4900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 5900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 6900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 7900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 8900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9000 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9100 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9200 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9300 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9400 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9500 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9600 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9700 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9800 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n",
            "Epoch: 9900 | Loss: 0.0004444979131221771 | Test loss: 0.0005780101055279374\n",
            "Model state_dict(): OrderedDict([('weights', tensor([0.6997])), ('bias', tensor([0.3008]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EseGTz0d3qyB",
        "outputId": "bc472bca-2ff0-40ec-8831-9c560dae0440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6994])), ('bias', tensor([0.2998]))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight, bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3YHdJki3vz-",
        "outputId": "8cad5e7b-c493-4ec1-e677-b2d8bc63d1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values).cpu().numpy()), label=\"Train loss\")\n",
        "plt.plot(epoch_count, np.array(torch.tensor(test_loss_values).cpu().numpy()), label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "7d9vnPgzmfVO",
        "outputId": "0ba8bfde-cf3c-43cc-ac02-827be3d6c75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b5facd3ccd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred = model_0(X_test[3])\n",
        "\n",
        "print(y_pred)\n",
        "print(y_test[3])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZeDNyEgXEkF",
        "outputId": "f40315cf-74eb-4c48-d091-7c8f84116cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9013])\n",
            "tensor([0.9020])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)\n"
      ],
      "metadata": {
        "id": "ww2qcui6dcXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "byEt1AYWfHzH",
        "outputId": "76107208-c3db-4746-8975-b4af9a14faa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving a model in PyTorch\n",
        "\n",
        "There are 3 main methods you should know about for saving and loading models in Pytorch.\n",
        "\n",
        "1. `torch.save()` - allows you to save a Pytorch object in Python's pickle format\n",
        "2. `torch.load()` - allows you to load a saved PyTorch object\n",
        "3. `torch.nn.Module.load_state_dict()` - allows you to load a model's saved state dictionary\n",
        "\n",
        "PyTorch save and load code tutorial: https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference"
      ],
      "metadata": {
        "id": "YQDYXNRBfKFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our PyTorch model\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state_dict\n",
        "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "3PTHR18mkzjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w6mh0zNnafm",
        "outputId": "22dbb71a-5275-4125-fa7b-af42a2bc3744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "-rw-r--r-- 1 root root 1680 Feb 26 17:47 01_pytorch_workflow_model_0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a PyTorch model\n",
        "\n",
        "Since we saved our model's `state-dict` rather the entire model, we'll create a new instance of our model class und load the saved `state_dict()` into that."
      ],
      "metadata": {
        "id": "SM_0aWI3ohYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2bdW3288PPn",
        "outputId": "f828af05-6ef2-46b5-ac01-b8f24dd17e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6994])), ('bias', tensor([0.2998]))])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load in a saved state-dict we have to instantiate a new instance of our model class\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
        "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVb4WM4L8TvT",
        "outputId": "c0db1a07-1077-4d0e-f10a-0b646b5ae5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-81172f6489a5>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkGEm_xA8sci",
        "outputId": "ecc6f35c-8988-4464-a4ff-f336a75fbafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.6994])), ('bias', tensor([0.2998]))])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our loaded model\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(X_test)\n",
        "\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDBF_qOH9dom",
        "outputId": "3060f948-8fc5-4547-da6b-f43989eb5bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8593],\n",
              "        [0.8733],\n",
              "        [0.8873],\n",
              "        [0.9013],\n",
              "        [0.9152],\n",
              "        [0.9292],\n",
              "        [0.9432],\n",
              "        [0.9572],\n",
              "        [0.9712],\n",
              "        [0.9852]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some models preds\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  model_0_preds = model_0(X_test)\n",
        "\n",
        "model_0_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFQUCivF9yEq",
        "outputId": "56db808a-6061-4bcf-b05e-34776c7b0b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8593],\n",
              "        [0.8733],\n",
              "        [0.8873],\n",
              "        [0.9013],\n",
              "        [0.9152],\n",
              "        [0.9292],\n",
              "        [0.9432],\n",
              "        [0.9572],\n",
              "        [0.9712],\n",
              "        [0.9852]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare loaded model preds with original model preds\n",
        "model_0_preds == loaded_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clujk3vJ98yk",
        "outputId": "f287d865-f3b2-4594-ca5e-15dc7c5b04b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Putting it all together\n",
        "\n",
        "Let's go back through the steps above and see it all in one place."
      ],
      "metadata": {
        "id": "NyggJjNq-I52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch and matplotlib\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "Ry86oHdo-9Gc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90d51919-fe8e-4ddc-c95b-6b5d6fc6e65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create device-agnostic code.\n",
        "\n",
        "This means if we've got access to a GPU, our code will use it (for potentially faster computing).\n",
        "\n",
        "If no GPU is available, the code will deafult to using CPU."
      ],
      "metadata": {
        "id": "hstlWxHHYMLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ztKflFAYrjv",
        "outputId": "31190c91-bc18-422d-e4c0-8f1501b38819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOmThP1CaqKq",
        "outputId": "4399d7bf-033e-4017-d0a5-00154cd3d045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 27 22:07:03 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Data"
      ],
      "metadata": {
        "id": "LdWs1tEj-57v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create some data using the linear regression formula of y= weight * X + bias\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create range values\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "# Create X and y (features and labels)\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1) # Without unsqueeze, errors will pop up\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL5f4o3KazW_",
        "outputId": "3396a793-f968-44f4-a360-b590cff7f9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlhApnNqbq2n",
        "outputId": "2e5f16f3-d39f-4a43-8c34-0055552662d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data\n",
        "# Note: If you don't have the plot_predictions() function loaded, this will error\n",
        "plot_predictions(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "uPUej13scKEL",
        "outputId": "96361814-2320-4e5e-99cc-275b0afbf212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Building a PyTorch Linear model"
      ],
      "metadata": {
        "id": "ekkql5vKch2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a linear model by subclassing nn.Module"
      ],
      "metadata": {
        "id": "5G1EifUfdhh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Use nn.Linear() for creating the model parameters / also called: linear transform, probing layer, fully connected layer, dense layer\n",
        "    self.linear_layer = nn.Linear(in_features=1, out_features=1, bias=True)\n",
        "\n",
        "  def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "# Set the manual seed\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDByMWcEc1Uy",
        "outputId": "d146ebaa-65ce-4031-9b2d-e5c0a80d4f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(LinearRegressionModelV2(\n",
              "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              " ),\n",
              " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "              ('linear_layer.bias', tensor([0.8300]))]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the model current device\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOPeQ5u5ghDP",
        "outputId": "ea2bc259-5edd-4dbb-e749-155020b8e04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to use the target device\n",
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_6vrJtLfU0W",
        "outputId": "eac2a5e3-7a59-4414-b113-49a3c794b6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 Training\n",
        "\n",
        "For training we need:\n",
        "* Loss function\n",
        "* Optimizer\n",
        "* Training loop\n",
        "* Testing loop"
      ],
      "metadata": {
        "id": "shWw0oUlgoOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loss function\n",
        "loss_fn = nn.L1Loss() # same as MAE\n",
        "\n",
        "# Setup the optimizer\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.0001)\n"
      ],
      "metadata": {
        "id": "PTXK5moThC2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's write a training loop\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 20000\n",
        "\n",
        "# Put data on the target device (device agnostic code for data)\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_1(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backporpagation\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Optimizer step\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_1(X_test)\n",
        "\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  # Print out what's happening\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-EYCnEgc8Cf",
        "outputId": "08013955-1e61-450d-a014-7c604e7cd28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.0012645035749301314 | Test loss: 0.0004654884396586567\n",
            "Epoch: 10 | Loss: 0.0007776893908157945 | Test loss: 0.001172184944152832\n",
            "Epoch: 20 | Loss: 0.000683495425619185 | Test loss: 0.0013786613708361983\n",
            "Epoch: 30 | Loss: 0.0006389491609297693 | Test loss: 0.0014137625694274902\n",
            "Epoch: 40 | Loss: 0.0006036348640918732 | Test loss: 0.0013722599251195788\n",
            "Epoch: 50 | Loss: 0.0005684852949343622 | Test loss: 0.0013238966930657625\n",
            "Epoch: 60 | Loss: 0.0005341582000255585 | Test loss: 0.0012412130599841475\n",
            "Epoch: 70 | Loss: 0.0004997484502382576 | Test loss: 0.0011585295433178544\n",
            "Epoch: 80 | Loss: 0.00046540648327209055 | Test loss: 0.0010827064979821444\n",
            "Epoch: 90 | Loss: 0.0004310697258915752 | Test loss: 0.0010000228649005294\n",
            "Epoch: 100 | Loss: 0.00039666518568992615 | Test loss: 0.0009173393482342362\n",
            "Epoch: 110 | Loss: 0.0003623247321229428 | Test loss: 0.0008415222400799394\n",
            "Epoch: 120 | Loss: 0.00032798349275253713 | Test loss: 0.0007588386652059853\n",
            "Epoch: 130 | Loss: 0.00029357895255088806 | Test loss: 0.0006761550903320312\n",
            "Epoch: 140 | Loss: 0.00025924594956450164 | Test loss: 0.0006003320449963212\n",
            "Epoch: 150 | Loss: 0.00022489727416541427 | Test loss: 0.0005176484701223671\n",
            "Epoch: 160 | Loss: 0.00019049123511649668 | Test loss: 0.0004349648952484131\n",
            "Epoch: 170 | Loss: 0.00015616566815879196 | Test loss: 0.0003591477870941162\n",
            "Epoch: 180 | Loss: 0.00012181401689304039 | Test loss: 0.0002764642413239926\n",
            "Epoch: 190 | Loss: 8.74094694154337e-05 | Test loss: 0.00019378066645003855\n",
            "Epoch: 200 | Loss: 5.308315303409472e-05 | Test loss: 0.00011795759201049805\n",
            "Epoch: 210 | Loss: 1.8744171029538848e-05 | Test loss: 2.8461217880249023e-05\n",
            "Epoch: 220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 1990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 2990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 3990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 4990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 5990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 6990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 7990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 8990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 9990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 10990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 11990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 12990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 13990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 14990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 15990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 16990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 17990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 18990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19000 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19010 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19020 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19030 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19040 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19050 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19060 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19070 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19080 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19090 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19100 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19110 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19120 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19130 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19140 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19150 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19160 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19170 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19180 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19190 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19200 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19210 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19220 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19230 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19240 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19250 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19260 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19270 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19280 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19290 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19300 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19310 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19320 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19330 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19340 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19350 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19360 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19370 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19380 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19390 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19400 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19410 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19420 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19430 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19440 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19450 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19460 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19470 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19480 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19490 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19500 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19510 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19520 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19530 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19540 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19550 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19560 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19570 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19580 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19590 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19600 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19610 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19620 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19630 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19640 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19650 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19660 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19670 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19680 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19690 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19700 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19710 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19720 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19730 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19740 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19750 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19760 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19770 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19780 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19790 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19800 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19810 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19820 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19830 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19840 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19850 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19860 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19870 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19880 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19890 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19900 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19910 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19920 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19930 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19940 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19950 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19960 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19970 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19980 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n",
            "Epoch: 19990 | Loss: 4.9667061830405146e-05 | Test loss: 5.067586971563287e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifnAlQbOeLen",
        "outputId": "3685c812-484d-43ce-bc81-319f67abccd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.6999]], device='cuda:0')),\n",
              "             ('linear_layer.bias', tensor([0.3000], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight,bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwR32g1Fe1vn",
        "outputId": "9e1a44f1-27b3-415d-a358-f356513b5570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Making and evaluating predictions"
      ],
      "metadata": {
        "id": "-xBbtP3pg31M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn model intro evaluation mode\n",
        "model_1.eval()\n",
        "\n",
        "# Make predictions on the test data\n",
        "with torch.inference_mode():\n",
        "  preds = model_1(X_test)\n",
        "\n",
        "plot_predictions(predictions=preds.cpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "AjheXDUpe4p5",
        "outputId": "1963e674-9d2c-4a3a-a26b-fe0a451f8592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.5 Saving and loading a trained model"
      ],
      "metadata": {
        "id": "OnzDEeLzfdO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our PyTorch model\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state_dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_1.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwCrIpIviLNH",
        "outputId": "a2442d01-4533-4b14-cfd5-e8c924632f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/01_pytorch_workflow_model_1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF31NeWCiaA2",
        "outputId": "c4068513-bc3b-4fda-cc75-04a88fcd8561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "-rw-r--r-- 1 root root 1744 Feb 27 22:40 01_pytorch_workflow_model_1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a PyTorch model\n",
        "\n",
        "# Create a new instance of linear regression model V2\n",
        "loaded_model_1 = LinearRegressionModelV2()\n",
        "\n",
        "# Load the saved state_dict of model_1\n",
        "loaded_model_1.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Put the loaded model to device\n",
        "loaded_model_1.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JMOlty6idVf",
        "outputId": "17890b6f-83dd-48af-98e7-1343cf85cf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-9145f8a01640>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model_1.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModelV2(\n",
              "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check on what device the loaded model runs\n",
        "next(loaded_model_1.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3CJExh4mTU2",
        "outputId": "44527042-983d-456e-ea27-03f440c11921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_1.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtx7Om4OmVxY",
        "outputId": "bda72831-93c6-4154-ccba-ed6ed8511dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.6999]], device='cuda:0')),\n",
              "             ('linear_layer.bias', tensor([0.3000], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model\n",
        "loaded_model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_1_preds = loaded_model_1(X_test)\n",
        "\n",
        "plot_predictions(predictions=loaded_model_1_preds.cpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "YG9O7diPihQN",
        "outputId": "bcbb04a0-bc7c-4616-d997-ead18e81dbe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds == loaded_model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmBEH3WFmvb9",
        "outputId": "91108d17-f3ee-415f-cf86-b24bdb428768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises & Extra-curriculum\n",
        "\n",
        "For exercise & extra-curriculum, refer to: https://www.learnpytorch.io/01_pytorch_workflow/#exercises"
      ],
      "metadata": {
        "id": "-WCGwH7WmxuF"
      }
    }
  ]
}